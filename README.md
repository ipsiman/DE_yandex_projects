## Проекты, реализованные во время обучения на программе "Инженер Данных" Яндекс.Практикум

### 1. Актуализация модели данных
Необходимо создать витрину данных для RFM-классификации пользователей приложения. Заказчик — компания, которая разрабатывает приложение по доставке еды.

### 2. Работа по DWH и пересмотру модели данных
Необходимо сделать миграцию в отдельные логические таблицы, а затем собрать на них витрину данных. Это поможет оптимизировать нагрузку на хранилище и позволит аналитикам, перед которыми стоит задача построить анализ эффективности и прибыльности бизнеса, отвечать на точечные вопросы о тарифах вендоров, стоимости доставки в разные страны, количестве доставленных заказов за последнюю неделю. Если искать эти данные в таблице исходных логов доставки, нагрузка на хранилище будет не оптимальна. Придется усложнять запросы, что может привести к ошибкам.

### 3. ETL и автоматизация подготовки данных
Необходимо адаптировать пайплайн для текущей задачи.
На основе пайплайна из сквозной задачи наполнить витрину данными по «возвращаемости клиентов» в разрезе недель.

### 4. Проектирование и разработка проверки
Краткое описание доработок и раздел об управлении ETL-процессом с проверками из задачи.

### 5. DWH для нескольких источников
Предстоит усовершенствовать хранилище: добавить новый источник и витрину. При этом данные из нового источника необходимо связать с данными, которые уже лежат в хранилище.

### 6. Работа по аналитическим базам данных (Vertica, Data Vault)
Предстоит пойти дальше — развить свою БД и ответить на следующий вопрос бизнеса. В рамках проекта нужно расширить модель данных, проанализировать новую информацию и помочь маркетологам дать эффективную рекламу соцсети в интернете.

### 7. Организации Data Lake (Spark)
Соцсеть, для которой мы построили Data Lake, развивается — пробный запуск в Австралии оказался удачным. Команда готовится к разработке обновлений. Значит, структуру хранилища предстоит переделать, а данные — дополнить. Этим мы и займётесь в проекте.

### 8. Потоковая обработка данных (Kafka)
Приложение, которое будет сужать круг пользователей и доставлять уведомления об акциях с ограниченным сроком действия. 

### 9. Облачные технологии (Kubernetes, Kafka, Redis)
Нужно реализовать микро-сервисы, которые заполняют слои STG, DDS и CDM, и визуализировать данные из витрины в дашборде.

### 10. Командный проект-хакатон
Задача построить хранилище данных, процесс загрузки данных в него, дашборд для аналитиков, а также описать решение в базовой документации. Хранилище и процесс нужны, чтобы обновление дашбордов в будущем могло происходить без значительных доработок системы, если бизнесу проект покажется перспективным. При этом система должна быть спроектирована и работать так, чтобы можно было при необходимости всё пересчитать.

### 11. Итоговый проект (DWH, Vertica, Airflow, Metabase)
Необходимо реализовать пайплайн обработки данных из источников и хранилище для финтех-стартапа. 

Выгрузка данных из PostgreSQL или S3 в DWH с помощью DAG в Airflow: обработка информации в рамках ETL-процесса.

Хранилище в компании должно быть реализовано на Vertica. После построения пайплайна обработки данных необходимо отдельно реализовать пайплайн формирования витрины с помощью Airflow и DAG. Необходимо также реализовать BI-аналитику для компании: подключиться из Metabase к Vertica и реализовать дашборд.
