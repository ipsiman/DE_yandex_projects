## Проекты, реализованные во время обучения на программе "Инженер Данных" Яндекс.Практикум

### 1. Создание витрины данных для RFM-классификации пользователей агрегатора доставки еды
- построение витрин данных;
- проверка качества данных.

*Инструменты: SQL, Postgre SQL*

### 2. Оптимизация модели данных интернет-магазина
- работа со слоями данных в хранилище; 
- работа с таблицами фактов и справочников; 
- дедупликация данных.

*Инструменты: Postgre SQL, SQL, Python*

### 3. Обновление пайплайна обработки данных 
- построение ETL-пайплайна;
- автоматическое обновление витрин данных.

*Инструменты: Python, Airflow, S3, Postgre SQL, REST-API*

### 4. Реализация витрины для расчётов выплат курьерам
- построение DWH; 
- написание ETL-пайплайна.

*Инструменты: Postgre SQL, Airflow, REST-API, Python, MongoDB*
  
### 5. Поиск сообществ с высокой конверсией в первое сообщение
- проектирование хранилища на колоночных базах данных;
- проектирование моделей хранения данных;
- проектирование ETL-пайплайнов между холодным хранилищем и колоночной базой данных.

*Инструменты: S3, REST-API, Postgre SQL, Airflow, Vetrica, Data Vault*

### 6. Обновление хранилища данных для соцсети
- построение Data Lake;
- построение пайплайнов обработки данных с использованием Apache Spark.

*Инструменты: Hadoop, MapReduce, HDFS, Apache Spark*

### 7. Настройка потоковой обработки данных для агрегатора доставки еды
- построение системы потоковой обработки с использованием Apache Spark Structured Streaming;
- работа с брокером сообщений Kafka; 
- объединение потоковых и статических данных;
- дедупликация данных при потоковой обработке.

*Инструменты: Kafka, Spark Streaming, PySpark, Postgre SQL, Python*

### 8. Создание DWH с использованием облачных технологий для агрегатора доставки еды
- создание микросервисов;
- потоковая обработка данных;
- развёртывание инфраструктуры в Yandex Cloud.

*Инструменты: Yandex Cloud, Kubernetes, Redis, Postgre SQL, Docker, Python, Kafka, SQL, DataLens*

### 9. Создание хранилища данных, процесса загрузки данных в него, дашборд для аналитиков
- построение DWH;
- построение пайплайнов обработки данных с использованием Apache Spark.
- построение витрин данных;

*Инструменты: Postgre SQL, Python, Kafka, SQL, HDFS, Apache Spark, Metabase*

### 10. Реализация пайплайна обработки данных из источников и хранилище для финтех-стартапа
- проектирование хранилища на колоночных базах данных;
- построение ETL-пайплайна;
- построение витрин данных;
- автоматическое обновление витрин данных.

*Инструменты: Postgre SQL, Python, SQL, Airflow, Vetrica, Metabase*
